{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e031b3a0-ab78-46b5-aa9c-d13941214152",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78631d72-0379-4ccb-b426-f59fd4020f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa7529d-0dcd-4f94-a4ce-68d53c39e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27480ba0-d890-4a38-a402-b9b85d01d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40454d78-ed52-4230-906c-e9f27f8ff0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partner_id</th>\n",
       "      <th>specialist_id</th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>province_id</th>\n",
       "      <th>age</th>\n",
       "      <th>reason_combind</th>\n",
       "      <th>specialist_name</th>\n",
       "      <th>correct_prediction</th>\n",
       "      <th>ids</th>\n",
       "      <th>logs</th>\n",
       "      <th>processed_symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>mất ngủ</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mất ngủ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>rối loạn thần kinh thực vật</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rối loạn thần kinh thực vật</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>đau đầu</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>đau đầu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>đau đầu,đau sau ngực gần phổi</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>đau đầu, đau sau ngực gốc phổi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>co giật 3 lần</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>có giật 3 lần</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   partner_id  specialist_id  status  gender  province_id  age  \\\n",
       "0           2             18       2     NaN            1   57   \n",
       "1           4             18       2     NaN            1   35   \n",
       "2           4             18       2     NaN           11   36   \n",
       "3           4             18       2     NaN            1   40   \n",
       "4           3             18       2     NaN            1   12   \n",
       "\n",
       "                      reason_combind specialist_name  correct_prediction  ids  \\\n",
       "0                          mất ngủ       thần kinh                 NaN  NaN   \n",
       "1   rối loạn thần kinh thực vật       thần kinh                 NaN  NaN   \n",
       "2                           đau đầu       thần kinh                 NaN  NaN   \n",
       "3  đau đầu,đau sau ngực gần phổi       thần kinh                 NaN  NaN   \n",
       "4                    co giật 3 lần       thần kinh                 NaN  NaN   \n",
       "\n",
       "  logs              processed_symptoms  \n",
       "0  NaN                         mất ngủ  \n",
       "1  NaN     rối loạn thần kinh thực vật  \n",
       "2  NaN                         đau đầu  \n",
       "3  NaN  đau đầu, đau sau ngực gốc phổi  \n",
       "4  NaN                   có giật 3 lần  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_version3/dataset_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a6808f-6aea-4ef5-b902-9ef7bbb4f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].fillna('unknown')\n",
    "df['gender'] = df['gender'].replace({1.0: 'female', 0.0: 'male'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2011a8f-ed25-467f-8af1-33f3cf5513e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_category\n",
      "adult      34894\n",
      "unknown    13124\n",
      "child       5606\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['age'] = df['age'].fillna(0)\n",
    "df['age_category'] = df['age'].apply(lambda x: \n",
    "                                                     'unknown' if x == 0 else \n",
    "                                                     'child' if 0 < x <= 15 else \n",
    "                                                     'adult')\n",
    "# Display the results\n",
    "print(df['age_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f847ec-4fb4-444f-ac28-1b88471a90d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after filtering for non-null processed_symptoms: 45959\n",
      "Percentage of data retained: 100.00%\n"
     ]
    }
   ],
   "source": [
    "df.shape# Filter data to keep only records with non-null processed_symptoms\n",
    "processed_df = df.dropna(subset=['processed_symptoms'])\n",
    "\n",
    "# Check the shape after filtering\n",
    "print(f\"Number of records after filtering for non-null processed_symptoms: {processed_df.shape[0]}\")\n",
    "print(f\"Percentage of data retained: {processed_df.shape[0]/len(processed_df)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70eb4fb4-afa6-469d-9bc1-7fe2ca137ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thần kinh', 'vô sinh - hiếm muộn', 'nhi khoa', 'thận - tiết niệu',\n",
       "       'ung bướu', 'hô hấp - phổi', 'chuyên khoa mắt', 'cơ xương khớp',\n",
       "       'nha khoa', 'tim mạch', 'tiêu hoá', 'sức khỏe tâm thần',\n",
       "       'nội khoa', 'tiểu đường - nội tiết', 'tai mũi họng', 'nam học',\n",
       "       'da liễu', 'sản phụ khoa'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.specialist_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f81de87-564e-44da-af5f-8a400e8a6445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples per class: specialist_id\n",
      "1     8029\n",
      "18    6897\n",
      "11    5113\n",
      "22    4123\n",
      "4     3824\n",
      "17    3680\n",
      "27    2998\n",
      "3     2622\n",
      "26    1953\n",
      "29    1462\n",
      "5     1358\n",
      "15    1068\n",
      "32     898\n",
      "43     613\n",
      "21     593\n",
      "19     285\n",
      "33     272\n",
      "67     171\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = processed_df['specialist_id'].value_counts()\n",
    "print(f'number of samples per class: {class_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5ac32b-ccd7-48a8-a4b7-d1b03d039496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y = df['specialist_id']\n",
    "weight_class = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6893b0a6-22ea-4670-a500-1bb4325563db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.33182347,  0.93889414,  0.72555068,  2.03075059,  0.54602476,\n",
       "         2.18891338,  0.65388743,  0.3957374 ,  1.85845983,  3.91473208,\n",
       "         0.58402492,  1.28965849,  0.89732262,  1.87483393,  2.71074714,\n",
       "         9.51792687,  4.58324786, 11.77514273]),\n",
       " 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_class, len(weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "040ebe57-174a-4a78-bfcd-9affc9f961f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weight_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "869e7686-eecc-4309-a7e6-01330b4f00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of specialists missing from processed_df: 0\n",
      "Missing specialists: set()\n",
      "Final processed_df shape: (45959, 13)\n",
      "Number of specialists in final dataset: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5751/1979069976.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_df['reason_combind'] = processed_df['processed_symptoms']\n"
     ]
    }
   ],
   "source": [
    "processed_df['reason_combind'] = processed_df['processed_symptoms']\n",
    "\n",
    "missing_specialists = set(df['specialist_name'].unique()) - set(processed_df['specialist_name'].unique())\n",
    "print(f\"Number of specialists missing from processed_df: {len(missing_specialists)}\")\n",
    "print(f\"Missing specialists: {missing_specialists}\")\n",
    "\n",
    "# Add records with missing specialists from df to processed_df\n",
    "if len(missing_specialists) > 0:\n",
    "    missing_df = pd.DataFrame()\n",
    "    for specialist in missing_specialists:\n",
    "        specialist_data = df[df['specialist_name'] == specialist].copy()\n",
    "        \n",
    "        # Since there's no main_reason column, just use empty string for reason_combind\n",
    "        missing_df = pd.concat([missing_df, specialist_data])\n",
    "    \n",
    "    # Combine with processed_df\n",
    "    processed_df = pd.concat([processed_df, missing_df])\n",
    "    \n",
    "print(f\"Final processed_df shape: {processed_df.shape}\")\n",
    "print(f\"Number of specialists in final dataset: {len(processed_df['specialist_name'].unique())}\")\n",
    "\n",
    "# Replace the original df with processed_df for further processing\n",
    "df = processed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ea308f-0ffd-4817-9f51-692a0d99c7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['thần kinh', 'vô sinh - hiếm muộn', 'nhi khoa', 'thận - tiết niệu',\n",
       "        'ung bướu', 'hô hấp - phổi', 'chuyên khoa mắt', 'cơ xương khớp',\n",
       "        'nha khoa', 'tim mạch', 'tiêu hoá', 'sức khỏe tâm thần',\n",
       "        'nội khoa', 'tiểu đường - nội tiết', 'tai mũi họng', 'nam học',\n",
       "        'da liễu', 'sản phụ khoa'], dtype=object),\n",
       " 18,\n",
       " (53624, 13))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.specialist_name.unique(), len(df.specialist_name.unique()), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f9280a-3c45-450f-9f8d-c066e0e29066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.specialist_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef552ab-5a24-4df8-9fe0-b1040681f5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partner_id                0\n",
       "specialist_id             0\n",
       "status                    0\n",
       "gender                    0\n",
       "province_id               0\n",
       "age                       0\n",
       "reason_combind            2\n",
       "specialist_name           0\n",
       "correct_prediction    43185\n",
       "ids                   46013\n",
       "logs                  46013\n",
       "processed_symptoms     7665\n",
       "age_category              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdc64af7-0cac-4fa8-96c6-a7675dafd422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in balanced dataset: 15977\n",
      "specialist_name\n",
      "thần kinh                1000\n",
      "nhi khoa                 1000\n",
      "da liễu                  1000\n",
      "thận - tiết niệu         1000\n",
      "ung bướu                 1000\n",
      "chuyên khoa mắt          1000\n",
      "tim mạch                 1000\n",
      "cơ xương khớp            1000\n",
      "sức khỏe tâm thần        1000\n",
      "tiêu hoá                 1000\n",
      "sản phụ khoa             1000\n",
      "nam học                  1000\n",
      "nội khoa                 1000\n",
      "tai mũi họng             1000\n",
      "tiểu đường - nội tiết     761\n",
      "hô hấp - phổi             650\n",
      "nha khoa                  313\n",
      "vô sinh - hiếm muộn       253\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract data for model training\n",
    "# Take 1000 examples per specialist_name\n",
    "specialist_samples = {}\n",
    "\n",
    "# Get list of unique specialists\n",
    "specialists = df['specialist_name'].unique()\n",
    "\n",
    "# Sample 1000 examples per specialist (or all if fewer than 1000)\n",
    "balanced_df = pd.DataFrame()\n",
    "for specialist in specialists:\n",
    "    specialist_df = df[df['specialist_name'] == specialist]\n",
    "    if len(specialist_df) > 1000:\n",
    "        sampled_df = specialist_df.sample(1000, random_state=42)\n",
    "    else:\n",
    "        sampled_df = specialist_df\n",
    "    balanced_df = pd.concat([balanced_df, sampled_df])\n",
    "\n",
    "# Reset index of the final balanced dataset\n",
    "balanced_df = balanced_df.reset_index(drop=True)\n",
    "print(f\"Total samples in balanced dataset: {len(balanced_df)}\")\n",
    "print(balanced_df['specialist_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6ddf789-f211-4eda-80e4-def0da2f5de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partner_id</th>\n",
       "      <th>specialist_id</th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>province_id</th>\n",
       "      <th>age</th>\n",
       "      <th>reason_combind</th>\n",
       "      <th>specialist_name</th>\n",
       "      <th>correct_prediction</th>\n",
       "      <th>ids</th>\n",
       "      <th>logs</th>\n",
       "      <th>processed_symptoms</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>mắt ngứa đã nhiều năm</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mắt ngứa đã nhiều năm</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>ngủ chập chờn rung giật cả</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ngủ chập chờn rung giật cả</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>đau đầu 2 ngày chưa khỏi</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>đau đầu 2 ngày chưa khỏi</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>đau đầu không đáp, cảm giác các dây thần kinh ...</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>đau đầu không đáp, cảm giác các dây thần kinh ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>muốn khám động kinh do bác sĩ tư vấn!</td>\n",
       "      <td>thần kinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>muốn khám động kinh do bác sĩ tư vấn!</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15710</th>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>bị ngứa, sưng nổi mảng ở chân trái</td>\n",
       "      <td>da liễu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15711</th>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>da đầu nhiều gầu, nghi nhiễm nấm</td>\n",
       "      <td>da liễu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15712</th>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>ngứa không rõ lý do</td>\n",
       "      <td>da liễu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15713</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>mụn nhọt sát ngón tay cái</td>\n",
       "      <td>da liễu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15714</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>bé bị mẩn ngứa vào ban đêm</td>\n",
       "      <td>da liễu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15715 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       partner_id  specialist_id  status  gender  province_id  age  \\\n",
       "0               1             18       2  female           30   43   \n",
       "1              49             18       2  female            1   12   \n",
       "2               8             18       2  female            1   26   \n",
       "3               1             18       2  female           34    0   \n",
       "4              41             18       2  female            1    4   \n",
       "...           ...            ...     ...     ...          ...  ...   \n",
       "15710         109             11       2  female            6   29   \n",
       "15711          48             11       2  female            1   31   \n",
       "15712          48             11       2    male            1   26   \n",
       "15713           5             11       2    male            1    6   \n",
       "15714          32             11       2  female            1    4   \n",
       "\n",
       "                                          reason_combind specialist_name  \\\n",
       "0                                  mắt ngứa đã nhiều năm       thần kinh   \n",
       "1                             ngủ chập chờn rung giật cả       thần kinh   \n",
       "2                               đau đầu 2 ngày chưa khỏi       thần kinh   \n",
       "3      đau đầu không đáp, cảm giác các dây thần kinh ...       thần kinh   \n",
       "4                  muốn khám động kinh do bác sĩ tư vấn!       thần kinh   \n",
       "...                                                  ...             ...   \n",
       "15710                 bị ngứa, sưng nổi mảng ở chân trái         da liễu   \n",
       "15711                   da đầu nhiều gầu, nghi nhiễm nấm         da liễu   \n",
       "15712                                ngứa không rõ lý do         da liễu   \n",
       "15713                          mụn nhọt sát ngón tay cái         da liễu   \n",
       "15714                         bé bị mẩn ngứa vào ban đêm         da liễu   \n",
       "\n",
       "       correct_prediction  ids logs  \\\n",
       "0                     NaN  NaN  NaN   \n",
       "1                     NaN  NaN  NaN   \n",
       "2                     NaN  NaN  NaN   \n",
       "3                     NaN  NaN  NaN   \n",
       "4                     NaN  NaN  NaN   \n",
       "...                   ...  ...  ...   \n",
       "15710                 NaN  NaN  NaN   \n",
       "15711                 NaN  NaN  NaN   \n",
       "15712                 NaN  NaN  NaN   \n",
       "15713                 NaN  NaN  NaN   \n",
       "15714                 NaN  NaN  NaN   \n",
       "\n",
       "                                      processed_symptoms age_category  \n",
       "0                                  mắt ngứa đã nhiều năm        adult  \n",
       "1                             ngủ chập chờn rung giật cả        child  \n",
       "2                               đau đầu 2 ngày chưa khỏi        adult  \n",
       "3      đau đầu không đáp, cảm giác các dây thần kinh ...      unknown  \n",
       "4                  muốn khám động kinh do bác sĩ tư vấn!        child  \n",
       "...                                                  ...          ...  \n",
       "15710                                                NaN        adult  \n",
       "15711                                                NaN        adult  \n",
       "15712                                                NaN        adult  \n",
       "15713                                                NaN        child  \n",
       "15714                                                NaN        child  \n",
       "\n",
       "[15715 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a5250e1-5617-4710-bc29-f44b136b7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalSpecialistClassifer(nn.Module):\n",
    "    def __init__(self, num_specialists: int, model_name: str = \"BookingCare/gte-multilingual-base-v2.1\", user_feature_dim=2, dropout=0.2, load_pretrained=True, trust_remote_code=False):\n",
    "        super(MedicalSpecialistClassifer, self).__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_name, trust_remote_code=trust_remote_code)\n",
    "        if load_pretrained:\n",
    "            self.reason_encoder = AutoModel.from_pretrained(model_name, config=config, trust_remote_code=True)\n",
    "        else:\n",
    "            self.reason_encoder = AutoModel.from_config(config, trust_remote_code=True)\n",
    "        \n",
    "        for param in self.reason_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.reason_encoder_hidden_dim = self.reason_encoder.config.hidden_size\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.user_encoder = nn.Sequential(\n",
    "            nn.Linear(user_feature_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "            nn.Linear(128, 256),\n",
    "            self.relu\n",
    "        )\n",
    "\n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(self.reason_encoder_hidden_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "        )\n",
    "\n",
    "        self.level1_output = nn.Linear(512, num_specialists)\n",
    "\n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(self.reason_encoder_hidden_dim + 256 + 512, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            self.relu,\n",
    "            self.dropout\n",
    "        )\n",
    "        self.level2_output = nn.Linear(768, num_specialists)\n",
    "\n",
    "    def forward(self, reason_text_ids, reason_text_mask, user_info=None):\n",
    "        reason_outputs = self.reason_encoder(reason_text_ids, attention_mask=reason_text_mask)\n",
    "        reason_embedding = reason_outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        hidden1 = self.hidden_layer1(reason_embedding)\n",
    "\n",
    "        level1_logits = self.level1_output(hidden1)\n",
    "\n",
    "        if user_info is None:\n",
    "            return level1_logits, None\n",
    "\n",
    "        user_features = self.user_encoder(user_info)\n",
    "\n",
    "        combined_features = torch.cat((reason_embedding, hidden1, user_features), dim=1)\n",
    "\n",
    "        hidden2 = self.hidden_layer2(combined_features)\n",
    "        level2_logits = self.level2_output(hidden2)\n",
    "\n",
    "        return level1_logits, level2_logits\n",
    "\n",
    "    def predict(self, reason_text_ids, reason_text_mask, user_info=None, threshold=0.7):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            level1_logits, level2_logits = self.forward(reason_text_ids, reason_text_mask, user_info)\n",
    "            level1_probs = F.softmax(level1_logits, dim=1)\n",
    "            max_probs, preds = torch.max(level1_probs, dim=1)\n",
    "            final_preds = preds.clone()\n",
    "\n",
    "            if user_info is not None and level2_logits is not None:\n",
    "                for i, prob in enumerate(max_probs):\n",
    "                    final_preds[i] = torch.argmax(level2_logits[i])\n",
    "\n",
    "            return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32070d38-7bfc-4212-8182-39a86b43dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MedicalDataFrameDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 128\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        reason_text = row['reason_combind']\n",
    "        user_info = torch.tensor([row['gender'], row['age_category']], dtype=torch.float32)\n",
    "        label = row['specialist_name']\n",
    "        encoded = self.tokenizer(\n",
    "            reason_text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            \"reason_text_ids\": encoded['input_ids'].squeeze(0),\n",
    "            \"reason_text_mask\": encoded['attention_mask'].squeeze(0),\n",
    "            \"user_info\": user_info,\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2d3fde2-0712-4eb1-b378-d9476d341ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=5, patience=2, save_path=\"best_model.pt\"):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_level1 = 0\n",
    "        correct_combined = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training...\"):\n",
    "            reason_text_ids = batch['reason_text_ids'].to(device)\n",
    "            reason_text_mask = batch['reason_text_mask'].to(device)\n",
    "            user_info = batch.get('user_info', None)\n",
    "\n",
    "            if user_info is not None:\n",
    "                user_info = user_info.to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            level1_logits, level2_logits = model(\n",
    "                reason_text_ids,\n",
    "                reason_text_mask,\n",
    "                user_info\n",
    "            )\n",
    "\n",
    "            _, level1_preds = torch.max(level1_logits, dim=1)\n",
    "            correct_mask = (level1_preds == labels)\n",
    "            loss = criterion(level1_logits, labels)\n",
    "\n",
    "            if level2_logits is not None and (~correct_mask).any():\n",
    "                incorrect_indices = (~correct_mask).nonzero(as_tuple=True)[0]\n",
    "                level2_loss = criterion(level2_logits[incorrect_indices], labels[incorrect_indices])\n",
    "                loss += level2_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            correct_level1 += correct_mask.sum().item()\n",
    "\n",
    "            if level2_logits is not None:\n",
    "                _, level2_preds = torch.max(level2_logits, dim=1)\n",
    "                final_preds = torch.where(correct_mask, level1_preds, level2_preds)\n",
    "            else:\n",
    "                final_preds = level1_preds\n",
    "\n",
    "            correct_combined += (final_preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Train Loss: {running_loss / len(train_loader): .4f}\")\n",
    "        print(f\"Level 1 Accuracy: {100 * correct_level1 / total:.2f}\")\n",
    "        print(f\"Final Accuracy (with Level 2 fallback): {100 * correct_combined / total: .2f}%\\n\")\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_level1 = 0\n",
    "        correct_combined = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc='Validate...'):\n",
    "                reason_text_ids = batch['reason_text_ids'].to(device)\n",
    "                reason_text_mask = batch['reason_text_mask'].to(device)\n",
    "                user_info = batch.get('user_info', None)\n",
    "                if user_info is not None:\n",
    "                    user_info = user_info.to(device)\n",
    "\n",
    "                    for p in model.hidden_layer2.parameters():\n",
    "                        p.requires_grad = True\n",
    "                    for p in model.level2_output.parameters():\n",
    "                        p.requires_grad = True\n",
    "                else:\n",
    "                    for p in model.hidden_layer2.parameters():\n",
    "                        p.requires_grad = False\n",
    "                    for p in model.level2_output.parameters():\n",
    "                        p.requires_grad = False\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                level1_logits, level2_logits = model(\n",
    "                    reason_text_ids,\n",
    "                    reason_text_mask,\n",
    "                    user_info\n",
    "                )\n",
    "\n",
    "                _, level1_preds = torch.max(level1_logits, dim=1)\n",
    "                correct_mask = (level1_preds == labels)\n",
    "                loss = criterion(level1_logits, labels)\n",
    "                if level2_logits is not None and (~correct_mask).any():\n",
    "                    incorrect_indices = (~correct_mask).nonzero(as_tuple=True)[0]\n",
    "                    level2_loss = criterion(level2_logits[incorrect_indices], labels[incorrect_indices])\n",
    "                    loss += level2_loss\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                correct_level1 += correct_mask.sum().item()\n",
    "\n",
    "                if level2_logits is not None:\n",
    "                    _, level2_preds = torch.max(level2_logits, dim=1)\n",
    "                    final_preds = torch.where(correct_mask, level1_preds, level2_preds)\n",
    "                else:\n",
    "                    final_preds = level1_preds\n",
    "\n",
    "                correct_combined += (final_preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Validation level 1 Accuracy: {100 * correct_level1 / total:.2f}%\")\n",
    "        print(f\"Validation Final Accuracy (with Level 2 fallback): {100 * correct_combined / total:.2f}%\\n\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"Model saved.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5fbecc8-71a7-45e4-a97e-d7b8b47d89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eb2f700-b6db-4c24-8cce-f0c4a2ff0930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc394ddc-4192-476c-b176-818e810b4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('../models/gte/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "442c411c-0c10-4b32-aaf5-88bad7c687dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialist_encoder = LabelEncoder()\n",
    "age_encoder = LabelEncoder()\n",
    "gender_encoder = LabelEncoder()\n",
    "df['age_category'] = age_encoder.fit_transform(df['age_category'])\n",
    "df['gender'] = gender_encoder.fit_transform(df['gender'])\n",
    "df['specialist_name'] = specialist_encoder.fit_transform(df['specialist_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91b48e69-961e-4890-b9a5-83de3f9b8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MedicalDataFrameDataset(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c66db4-edc2-4531-9b09-6162430b02a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reason_text_ids': tensor([    0, 57695,  4868,    18, 27421,     2,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'reason_text_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'user_info': tensor([2., 0.]),\n",
       " 'labels': tensor(11)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6210f789-54dd-48d2-b091-94a6a7a49848",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3aa9ff1-15f9-4032-ab65-686d1f8f82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MedicalSpecialistClassifer(model_name = \"../models/gte/\",num_specialists=len(specialist_encoder.classes_), user_feature_dim=2, load_pretrained=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6be37109-96e7-4ca4-9867-67ae290b8569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedicalSpecialistClassifer(\n",
       "  (reason_encoder): NewModel(\n",
       "    (embeddings): NewEmbeddings(\n",
       "      (word_embeddings): Embedding(250048, 768, padding_idx=1)\n",
       "      (rotary_emb): NTKScalingRotaryEmbedding()\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): NewEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x NewLayer(\n",
       "          (attention): NewSdpaAttention(\n",
       "            (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (o_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (mlp): NewGatedMLP(\n",
       "            (up_gate_proj): Linear(in_features=768, out_features=6144, bias=False)\n",
       "            (down_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (act_fn): GELUActivation()\n",
       "            (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attn_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (mlp_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (user_encoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (hidden_layer1): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (level1_output): Linear(in_features=512, out_features=18, bias=True)\n",
       "  (hidden_layer2): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (level2_output): Linear(in_features=768, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04c16068-ed27-4fdd-afbc-dba7ba615d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49c413de-c46d-48c3-9e82-6341ed6fd6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_class = torch.tensor(weight_class, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "369618a0-8d9a-4976-8331-82003c9d8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c232a3f-ad44-4c20-8de7-47fe31d456ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cd34cb82de4670a00a9d59fe741318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e55da21b9bd4ddb9f6ece6c4587a491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/3352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device, num_epochs, patience, save_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m correct_combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m     reason_text_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreason_text_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     reason_text_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreason_text_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m, in \u001b[0;36mMedicalDataFrameDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m user_info \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_category\u001b[39m\u001b[38;5;124m'\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     17\u001b[0m label \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecialist_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreason_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreason_text_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreason_text_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_info,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     30\u001b[0m }\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2887\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2887\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/projects/specialist-prediction/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2947\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2944\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2950\u001b[0m     )\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2956\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=30, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3543f0bc-d6da-4698-8185-722e51e8505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = MedicalSpecialistClassifer(num_specialists=len(specialist_encoder.classes_), user_feature_dim=2, load_pretrained=False, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45653a7f-fdd2-4779-80ba-b0301d7aee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save encoders to pickle files\n",
    "with open(\"specialist_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(specialist_encoder, f)\n",
    "    \n",
    "with open(\"age_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(age_encoder, f)\n",
    "    \n",
    "with open(\"gender_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gender_encoder, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40a2b1ff-8995-4aaa-8774-6027e3b27ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(specialist_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1141db4f-c451-413d-a3ab-1cc3ac89deb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedicalSpecialistClassifer(\n",
       "  (reason_encoder): NewModel(\n",
       "    (embeddings): NewEmbeddings(\n",
       "      (word_embeddings): Embedding(250048, 768, padding_idx=1)\n",
       "      (rotary_emb): NTKScalingRotaryEmbedding()\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): NewEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x NewLayer(\n",
       "          (attention): NewSdpaAttention(\n",
       "            (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (o_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (mlp): NewGatedMLP(\n",
       "            (up_gate_proj): Linear(in_features=768, out_features=6144, bias=False)\n",
       "            (down_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (act_fn): GELUActivation()\n",
       "            (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attn_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (mlp_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (hidden_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (user_encoder): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (hidden_layer1): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (level1_output): Linear(in_features=512, out_features=17, bias=True)\n",
       "  (hidden_layer2): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (level2_output): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3fe3645f-10bc-413c-b47e-88f856cf6e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(torch.load(\"../notebooks/best_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7869ff3a-606d-452d-ac97-cefa2f314c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.eval()\n",
    "reason_text = \"lười ăn, không tăng cân, constipation\"\n",
    "data = tokenizer(\n",
    "    reason_text,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "age_category = \"child\"\n",
    "gender = \"male\"\n",
    "\n",
    "# Fix the tensor shape for user_info\n",
    "user_info = torch.tensor([[gender_encoder.transform([gender])[0], age_encoder.transform([age_category])[0]]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6567deb4-a2d3-410f-a1cf-942be03f1631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[     0,     96, 150365,   6687,      4,    687,  11122,  24376,      4,\n",
       "             158,      7,  30019,   2320,      2,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]])},\n",
       " tensor([[1., 1.]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f29a64d8-4fe7-48f5-b560-e95d9cd5609b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(data['input_ids'], data['attention_mask'], user_info=user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ccd8608-947c-444c-92e5-35df4b6ed6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nampq/projects/specialist-prediction/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "res = specialist_encoder.inverse_transform([new_model.predict(data['input_ids'], data['attention_mask'], user_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0eb242a2-f7b6-4fde-b1f9-c05f5eefc668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nhi khoa']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71e0f4-0afc-4d3d-b31f-ae1007db841b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
